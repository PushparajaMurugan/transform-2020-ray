{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainables\n",
    "\n",
    "So far we have been using the functional interface to Raytune, which is lightweight and easy to get started with.\n",
    "\n",
    "However, is limited in a couple of ways (1) it doesn't allow us to maintain state (2) raytune cannot 'see' or manage training iterations (3) it doesn't let us use some other useful parts of Raytune like the checkpointing or schedulers.\n",
    "\n",
    "We'll take a look at a simple trainable below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dependencies we have already seen...\n",
      "Importing ray...\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dependencies import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable Interface\n",
    "\n",
    " 1. By subclassing tune.Trainable\n",
    " 2. Setup state in `__init__`\n",
    " 3. Implement `_train()` such that si completely one using unit/iteration of training\n",
    " 4. Implement `_save` to save state, checkpoint models, etc...\n",
    " 5. Implement `_restore` to, restore...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "class MyTrainable(tune.Trainable):\n",
    "    \n",
    "    \n",
    "    def _setup(self, config):\n",
    "        # config (dict): A dict of hyperparameters\n",
    "        self.x = 0\n",
    "        self.a = config[\"a\"]\n",
    "\n",
    "        \n",
    "    def _train(self):  # This is called iteratively.\n",
    "        self.x += self.a\n",
    "        print(\"Trainable\", f\"({self.a})\", self.x)\n",
    "        return {\"score\": self.x }\n",
    "    \n",
    "    \n",
    "    def _save(self, checkpoint_dir):\n",
    "        checkpoint_path = path.join(checkpoint_dir, \"model.npy\")\n",
    "        np.save(checkpoint_path, np.array(self.x))\n",
    "        return checkpoint_path\n",
    "\n",
    "    #\n",
    "    # Restore is used internally by Raytune and schedulers. \n",
    "    # It's only useful manually on single training runs.\n",
    "    #\n",
    "    def _restore(self, checkpoint_path):\n",
    "        print(\"CHECKPOINT PATH\", checkpoint_path)\n",
    "        self.x = np.load(checkpoint_path)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-12 11:16:54,184\tINFO resource_spec.py:204 -- Starting Ray with 32.91 GiB memory available for workers and up to 16.47 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-06-12 11:16:54,446\tINFO services.py:1168 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8267\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.39',\n",
       " 'raylet_ip_address': '192.168.1.39',\n",
       " 'redis_address': '192.168.1.39:56277',\n",
       " 'object_store_address': '/tmp/ray/session_2020-06-12_11-16-54_183366_135563/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-06-12_11-16-54_183366_135563/sockets/raylet',\n",
       " 'webui_url': 'localhost:8267',\n",
       " 'session_dir': '/tmp/ray/session_2020-06-12_11-16-54_183366_135563'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init(num_cpus=2, num_gpus=0, include_webui=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "\n",
    "Do some simple tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.4/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/2 CPUs, 0/0 GPUs, 0.0/32.91 GiB heap, 0.0/11.33 GiB objects<br>Result logdir: /home/steve/ray_results/my_trainable/simple_trainable<br>Number of trials: 2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  a</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>MyTrainable_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">  1</td></tr>\n",
       "<tr><td>MyTrainable_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">  2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for MyTrainable_00000:\n",
      "  date: 2020-06-12_11-16-55\n",
      "  done: false\n",
      "  experiment_id: b8aa5c204c254de78302230079b31d71\n",
      "  experiment_tag: 0_a=1\n",
      "  hostname: cosmos-ml\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.39\n",
      "  pid: 135798\n",
      "  score: 1\n",
      "  time_since_restore: 3.790855407714844e-05\n",
      "  time_this_iter_s: 3.790855407714844e-05\n",
      "  time_total_s: 3.790855407714844e-05\n",
      "  timestamp: 1591957015\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '00000'\n",
      "  \n",
      "Result for MyTrainable_00001:\u001b[2m\u001b[36m(pid=135798)\u001b[0m 2020-06-12 11:16:55,909\tINFO trainable.py:217 -- Getting current IP.\n",
      "  date: 2020-06-12_11-16-55\n",
      "  done: false\n",
      "  experiment_id: 1b8c21e83c984c8592d3ffa19882701a\n",
      "  experiment_tag: 1_a=2\n",
      "  hostname: cosmos-ml\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.39\n",
      "  pid: 135797\n",
      "  score: 2\n",
      "  time_since_restore: 2.7418136596679688e-05\n",
      "  time_this_iter_s: 2.7418136596679688e-05\n",
      "  time_total_s: 2.7418136596679688e-05\n",
      "  timestamp: 1591957015\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '00001'\n",
      "  \n",
      "\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 1\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 2\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 3\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 4\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 5\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m 2020-06-12 11:16:55,928\tINFO trainable.py:217 -- Getting current IP.\n",
      "Result for MyTrainable_00000:\n",
      "  date: 2020-06-12_11-16-55\n",
      "  done: true\n",
      "  experiment_id: b8aa5c204c254de78302230079b31d71\n",
      "  experiment_tag: 0_a=1\n",
      "  hostname: cosmos-ml\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.1.39\n",
      "  pid: 135798\n",
      "  score: 20\n",
      "  time_since_restore: 0.0005333423614501953\n",
      "  time_this_iter_s: 3.075599670410156e-05\n",
      "  time_total_s: 0.0005333423614501953\n",
      "  timestamp: 1591957015\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: '00000'\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 2\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 4\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 6\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 8\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 10\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 12\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 6\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 7\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 8\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 9\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 10\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 11\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 12\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 13\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 14\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 15\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 16\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 17\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 18\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 19\n",
      "\u001b[2m\u001b[36m(pid=135798)\u001b[0m Trainable (1) 20\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 14\n",
      "Result for MyTrainable_00001:\n",
      "  date: 2020-06-12_11-16-56\n",
      "  done: true\n",
      "  experiment_id: 1b8c21e83c984c8592d3ffa19882701a\n",
      "  experiment_tag: 1_a=2\n",
      "  hostname: cosmos-ml\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.1.39\n",
      "  pid: 135797\n",
      "  score: 40\n",
      "  time_since_restore: 0.0006971359252929688\n",
      "  time_this_iter_s: 3.719329833984375e-05\n",
      "  time_total_s: 0.0006971359252929688\n",
      "  timestamp: 1591957016\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: '00001'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.4/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/32.91 GiB heap, 0.0/11.33 GiB objects<br>Result logdir: /home/steve/ray_results/my_trainable/simple_trainable<br>Number of trials: 2 (2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  a</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>MyTrainable_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">     0.000533342</td></tr>\n",
       "<tr><td>MyTrainable_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">     0.000697136</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 16\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 18\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 20\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 22\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 24\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 26\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 28\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 30\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 32\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 34\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 36\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 38\n",
      "\u001b[2m\u001b[36m(pid=135797)\u001b[0m Trainable (2) 40\n",
      "best config:  {'a': 2}\n"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    MyTrainable,\n",
    "    name=\"simple_trainable\",\n",
    "    stop={\"training_iteration\": 20},\n",
    "    config={ \"a\": tune.grid_search([1,2]) },\n",
    "    checkpoint_freq=5,\n",
    "    resources_per_trial=dict(cpu=1, gpu=0),\n",
    "    local_dir=\"~/ray_results/my_trainable\")\n",
    "\n",
    "print('best config: ', analysis.get_best_config(metric=\"score\", mode=\"max\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go check the ray_results directory!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
