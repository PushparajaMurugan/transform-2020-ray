{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainables\n",
    "\n",
    "So far we have been using the functional interface to Raytune, which is lightweight and easy to get started with.\n",
    "\n",
    "However, is limited in a couple of ways (1) it doesn't allow us to maintain state (2) raytune cannot 'see' or manage training iterations (3) it doesn't let us use some other useful parts of Raytune like the checkpointing or schedulers.\n",
    "\n",
    "We'll take a look at a simple trainable below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dependencies we have already seen...\n",
      "Importing ray...\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dependencies import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable Interface\n",
    "\n",
    " 1. By subclassing tune.Trainable\n",
    " 2. Setup state in `__init__`\n",
    " 3. Implement `_train()` such that si completely one using unit/iteration of training\n",
    " 4. Implement `_save` to save state, checkpoint models, etc...\n",
    " 5. Implement `_restore` to, restore...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "class MyTrainable(tune.Trainable):\n",
    "    \n",
    "    \n",
    "    def _setup(self, config):\n",
    "        # config (dict): A dict of hyperparameters\n",
    "        self.x = 0\n",
    "        self.a = config[\"a\"]\n",
    "\n",
    "        \n",
    "    def _train(self):  # This is called iteratively.\n",
    "        self.x += self.a\n",
    "        print(\"Trainable\", f\"({self.a})\", self.x)\n",
    "        return {\"score\": self.x }\n",
    "    \n",
    "    \n",
    "    def _save(self, checkpoint_dir):\n",
    "        checkpoint_path = path.join(checkpoint_dir, \"model.npy\")\n",
    "        np.save(checkpoint_path, np.array(self.x))\n",
    "        return checkpoint_path\n",
    "\n",
    "    #\n",
    "    # Restore is used internally by Raytune and schedulers. \n",
    "    # It's only useful manually on single training runs.\n",
    "    #\n",
    "    def _restore(self, checkpoint_path):\n",
    "        print(\"CHECKPOINT PATH\", checkpoint_path)\n",
    "        self.x = np.load(checkpoint_path)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 16:43:56,206\tINFO resource_spec.py:204 -- Starting Ray with 35.84 GiB memory available for workers and up to 17.94 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-06-10 16:43:56,508\tINFO services.py:1168 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.39',\n",
       " 'raylet_ip_address': '192.168.1.39',\n",
       " 'redis_address': '192.168.1.39:18955',\n",
       " 'object_store_address': '/tmp/ray/session_2020-06-10_16-43-56_180499_14591/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-06-10_16-43-56_180499_14591/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-06-10_16-43-56_180499_14591'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init(num_cpus=2, num_gpus=0, include_webui=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "\n",
    "Do some simple tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    MyTrainable,\n",
    "    name=\"simple_trainable\",\n",
    "    stop={\"training_iteration\": 20},\n",
    "    config={ \"a\": tune.grid_search([1,2]) },\n",
    "    checkpoint_freq=5,\n",
    "    resources_per_trial=dict(cpu=1, gpu=0),\n",
    "    local_dir=\"~/ray_results/my_trainable\")\n",
    "\n",
    "print('best config: ', analysis.get_best_config(metric=\"score\", mode=\"max\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go check the ray_results directory!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
