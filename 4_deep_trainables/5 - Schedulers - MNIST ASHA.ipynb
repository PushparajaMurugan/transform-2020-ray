{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainable MNIST with AHSA\n",
    "\n",
    "\n",
    "ASHA - Asynchronous Hyprerband is a schedulign algorithm that can be used with Random and Grid searches that monitor training performance and stop models that are not performing.\n",
    "\n",
    "This frees up resources to launch other runs with potentially better parameters.\n",
    "\n",
    "[AHS Paper](https://arxiv.org/pdf/1810.05934.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dependencies import *\n",
    "from mnist_pytorch import get_data_loaders\n",
    "from mnist_training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init(num_cpus=6, num_gpus=1, include_webui=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the scheduler\n",
    "\n",
    "Adding ASHA is as simple as configuring the scheduler object replacing the `stop` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config={\n",
    "    \"lr\": tune.uniform(0.001, 0.1),\n",
    "    \"momentum\": tune.uniform(0.1, 0.9),\n",
    "}\n",
    "\n",
    "asha = tune.schedulers.AsyncHyperBandScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='mean_accuracy',\n",
    "    mode='max',\n",
    "    max_t=100,\n",
    "    grace_period=10,\n",
    "    reduction_factor=3,\n",
    "    brackets=3)\n",
    "\n",
    "analysis = tune.run(\n",
    "    TrainMNIST,\n",
    "    local_dir=\"~/ray_results/torch_mnist_asha\",\n",
    "    resources_per_trial={\n",
    "        \"cpu\": 1,\n",
    "        \"gpu\": 0\n",
    "    },\n",
    "    num_samples=15,\n",
    "    checkpoint_at_end=True,\n",
    "    checkpoint_freq=10,\n",
    "    keep_checkpoints_num=3,\n",
    "    scheduler=asha,\n",
    "#     stop={\n",
    "#         \"mean_accuracy\": 0.95,\n",
    "#         \"training_iteration\": 100,\n",
    "#     },\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best config is:\", analysis.get_best_config(metric=\"mean_accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "from tensorboard import notebook \n",
    "%tensorboard --logdir \"~/ray_results/torch_mnist_asha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercises\n",
    "# - change out the optimiser for adam\n",
    "# - add network hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
