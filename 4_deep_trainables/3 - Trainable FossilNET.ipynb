{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FossilNET Classification\n",
    "\n",
    "In this notebook, we are going to update a pre-trained ResNet network to target the FossilNET image dataset.\n",
    "\n",
    "\n",
    "## What is FossilNET?\n",
    "\n",
    "FossilNET is an image dataset collected and curated by [Matt Hall](https://github.com/kwinkunks). the dataset is mde available under [CC-0 License](../datsasets/fossilnet/fossilnet-copyright-info.md)\n",
    "\n",
    "The dataset consists of 3000 128x128 color images acrosss 10 classes. The full dataset is available for experimentation. \n",
    "\n",
    "In the tutorial we just target 4 classes:\n",
    "\n",
    "|  dinosaurs |  fishes  |  forams  |  trilobites\n",
    "|:---:|:---:|:---:|:---:\n",
    "| ![dino](../datasets/fossilnet/tvt_split/4/train/dinosaurs/00949.png) | ![fish](../datasets/fossilnet/tvt_split/4/train/fishes/01603.png) | ![forams](../datasets/fossilnet/tvt_split/4/train/forams/01923.png) | ![trilobites](../datasets/fossilnet/tvt_split/4/train/trilobites/02866.png)| | \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dependencies\n",
    "\n",
    "We load the usual deps and also load [PyTorch](https://pytorch.org/docs/stable/index.html) and the [TorchVision](https://pytorch.org/docs/stable/torchvision/index.html) helper library to get access to pretrained models, dataloaders & transformers for image problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dependencies import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "FossilNET is nicely organised on disk into train / val / test folders each of which contains a subfolder for each class with the appropraite images therein.\n",
    "\n",
    "This means we cna use a torchvision.dataset.ImageFolder to take care of loading and inject torchvision.transforms to pre-process and augment the dataset on the fly.\n",
    "\n",
    "So create a function to set that up for the train and val splits and return dataloaders ready for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(fossilnet_path,\n",
    "                     batch_size=16,\n",
    "                     augment_flip=True,\n",
    "                     use_grayscale=True):\n",
    "    \n",
    "    #\n",
    "    # We define an array (pipeline) of transformers that we then use Compose to present to the dataset\n",
    "    #\n",
    "    txs = []\n",
    "    \n",
    "    if use_grayscale:\n",
    "        # convert to gray but maintain 3 channels for resnet\n",
    "        txs.append(transforms.Grayscale(3))\n",
    "    \n",
    "    if augment_flip:\n",
    "        txs.extend([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip()\n",
    "        ])\n",
    "    \n",
    "    txs.append(transforms.ToTensor())\n",
    "    \n",
    "    if use_grayscale:\n",
    "        txs.append(transforms.Normalize(0.0, 1.0))\n",
    "\n",
    "    \n",
    "    #\n",
    "    # Use the torchvision ImageFolder Dataset class\n",
    "    #\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "                            root=path.join(fossilnet_path, 'train'),\n",
    "                            transform=transforms.Compose(txs)\n",
    "                        )\n",
    "    \n",
    "    #\n",
    "    # Setup a DataLoader to get batches of images for training\n",
    "    #\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=3,\n",
    "                              pin_memory=True)\n",
    "    \n",
    "    \n",
    "    #\n",
    "    # Setup a DataSet and Loader for the test data. This time without shuffle or\n",
    "    # augmentations enabled\n",
    "    #\n",
    "    val_txs = []\n",
    "    \n",
    "    if use_grayscale:\n",
    "        val_txs.extend([\n",
    "            transforms.Grayscale(3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(0.0, 1.0)\n",
    "        ])\n",
    "    else:\n",
    "        val_txs.append(transforms.ToTensor())\n",
    "    \n",
    "    val_dataset = datasets.ImageFolder(\n",
    "                            root=path.join(fossilnet_path, 'test'),\n",
    "                            transform=transforms.Compose(val_txs)\n",
    "                        )\n",
    "    \n",
    "    val_loader = DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=1,\n",
    "                            pin_memory=True)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Neural Network - We'll use ResNet18\n",
    "\n",
    "We setup a simple pytorch module, load the weights and reset the last layer only, which we will retrain for our targets\n",
    "\n",
    "[About ResNet18 Architecture](https://www.researchgate.net/figure/ResNet-18-Architecture_tbl1_322476121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cue cool name\n",
    "class FossilResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_outputs=10):\n",
    "        super(FossilResNet, self).__init__()\n",
    "        \n",
    "        # this will pull the weights down to a local cache on first execution\n",
    "        self.model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "        \n",
    "        # we turn of gradients on all layers, so the optimiser will ignore them during backward\n",
    "        for param in self.model_conv.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # we replace the last layer with a freshly initialised one, targeting the correct number of outputs,\n",
    "        # which will be optimised\n",
    "        num_ftrs = self.model_conv.fc.in_features\n",
    "        self.model_conv.fc = nn.Linear(num_ftrs, num_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model_conv(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validate functions\n",
    "\n",
    "We have seen train and test/validate functions a few times now, where we just loop over the datasets, calculate losses and metrics and return.\n",
    "\n",
    "This time train & Validate are called once per epoch and return f1_score over all examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train(model, optimizer, train_loader, device=None):\n",
    "    device = device or torch.device(\"cpu\")\n",
    "\n",
    "    #\n",
    "    # Accumulate labels and predicitons manually over all batches\n",
    "    #\n",
    "    y_all = []\n",
    "    y_class = []\n",
    "    \n",
    "    # iterate over all training batches\n",
    "    model.train()\n",
    "    for X, y in tqdm(train_loader, desc=\"Training...\"):\n",
    "\n",
    "        # send data to the gpu\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # zero gradients from last step\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # run forward pass\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # compute the loss\n",
    "        loss = F.nll_loss(y_pred, y)\n",
    "        \n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # step the optimiser\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep hold of target and compute y_class for metrics\n",
    "        y_all.extend(y.tolist())   \n",
    "        _, c = torch.max(y_pred, 1)\n",
    "        y_class.extend(c.tolist())\n",
    "        \n",
    "    #\n",
    "    # Compute f1 on all examples\n",
    "    #\n",
    "    return f1_score(y_all, y_class, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_loader, device=None):\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    \n",
    "    #\n",
    "    # Accumulate labels and predicitons manually over all batches\n",
    "    #\n",
    "    y_all = []\n",
    "    y_class = []\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(data_loader, desc=\"Testing...\"):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            y_pred = model(X).cpu()\n",
    "            \n",
    "            # keep hold of target and compute y_class for metrics\n",
    "            y_all.extend(y.tolist())   \n",
    "            _, c = torch.max(y_pred, 1)\n",
    "            y_class.extend(c.tolist())\n",
    "            \n",
    "    #\n",
    "    # Compute f1 on all examples\n",
    "    #\n",
    "\n",
    "    return f1_score(y_all, y_class, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Trainable Class\n",
    "\n",
    "We create a ray Trainable wrapper class as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "class FossilTrainable(tune.Trainable):\n",
    "    \n",
    "    def _setup(self, config):\n",
    "        # detect if cuda is availalbe as ray will assign GPUs if available and configured\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.train_loader, self.test_loader = get_data_loaders(\n",
    "            #\n",
    "            # This path needs to be right for you local system\n",
    "            #\n",
    "            path.expanduser('~/dev/transform-2020-ray-wip/datasets/fossilnet/tvt_split/4'),\n",
    "            batch_size=int(config.get(\"batch_size\", 16)),\n",
    "            augment_flip=config.get(\"augment_flip\", True),\n",
    "            use_grayscale=config.get(\"use_grayscale\", True)\n",
    "        )\n",
    "        \n",
    "        #\n",
    "        # Create the network\n",
    "        #\n",
    "        self.model = FossilResNet(num_outputs=4).to(self.device)\n",
    "        \n",
    "        #\n",
    "        # Setup the optimiser\n",
    "        #\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=config.get(\"lr\", 0.01),\n",
    "            weight_decay=config.get(\"weight_decay\", 1e-5)\n",
    "        )\n",
    "\n",
    "        #\n",
    "        # Use Trainable state to keep track of best scores\n",
    "        #\n",
    "        self._best_train_f1_score = 0.\n",
    "        self._best_val_f1_score = 0.\n",
    "        \n",
    "    def _train(self):\n",
    "        train_f1_score = train(self.model,\n",
    "                               self.optimizer,\n",
    "                               self.train_loader,\n",
    "                               device=self.device)\n",
    "        \n",
    "        val_f1_score = validate(self.model,\n",
    "                                self.test_loader,\n",
    "                                self.device)\n",
    "        \n",
    "        if (train_f1_score > self._best_train_f1_score):\n",
    "            self._best_train_f1_score = train_f1_score\n",
    "        \n",
    "        if (val_f1_score > self._best_val_f1_score):\n",
    "            self._best_val_f1_score = val_f1_score\n",
    "        \n",
    "        #\n",
    "        # Really we should return losses here too and we\n",
    "        # are free to extend the return dict with anything we want to track\n",
    "        #\n",
    "        return dict(\n",
    "            train_f1_score=train_f1_score,\n",
    "            best_train_f1_score = self._best_train_f1_score,\n",
    "            val_f1_score=val_f1_score,\n",
    "            best_val_f1_score=self._best_val_f1_score\n",
    "        )\n",
    "\n",
    "    def _save(self, checkpoint_dir):\n",
    "        checkpoint_path = path.join(checkpoint_dir, \"model.pth\")\n",
    "        torch.save(self.model.state_dict(), checkpoint_path)\n",
    "        return checkpoint_path\n",
    "    \n",
    "    def _restore(self, checkpoint_path):\n",
    "        self.model.load_state_dict(torch.load(checkpoint_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CUDA Available') if torch.cuda.is_available() else print('CPU Only')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init(num_cpus=3, num_gpus=1, include_webui=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Potential bug in tensorboard logging for tune.choice() working around that here\n",
    "# \n",
    "def _choice(items):\n",
    "    return items[np.random.randint(len(items))]\n",
    "\n",
    "\n",
    "#\n",
    "# Setup our Parameter Optimisation Space\n",
    "#\n",
    "config = dict(\n",
    "    lr=tune.uniform(1e-3, 1e-1),\n",
    "    weight_decay=tune.loguniform(1e-7, 1e-3),\n",
    "    batch_size=tune.sample_from(lambda x: _choice([8, 16, 32, 64])),\n",
    "    augment_flip=tune.sample_from(lambda x: _choice([True,False])),\n",
    "    use_grayscale=tune.sample_from(lambda x:_choice([True,False]))\n",
    ")\n",
    "\n",
    "#\n",
    "# Before commiting to a huge run, run training 1 iteration with N (10?) samples to dry run through different\n",
    "# hyperparameter options\n",
    "#\n",
    "# Then set this to False and tune for real\n",
    "#\n",
    "smoke_test = True\n",
    "\n",
    "analysis = tune.run(\n",
    "    FossilTrainable,\n",
    "    local_dir=\"~/ray_results/torch_fossilnet\",\n",
    "    resources_per_trial={\n",
    "        \"cpu\": 3,\n",
    "        \"gpu\": 1\n",
    "    },\n",
    "    num_samples=10 if smoke_test else 50,\n",
    "    checkpoint_at_end=True,\n",
    "    keep_checkpoints_num=5,\n",
    "    checkpoint_freq=10,\n",
    "    stop={\n",
    "        \"train_f1_score\": 0.95,\n",
    "        \"training_iteration\": 1 if smoke_test else 200,\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Best config is:\", analysis.get_best_config(metric=\"best_val_f1_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "Head over to EC2 and check results of a longer run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
