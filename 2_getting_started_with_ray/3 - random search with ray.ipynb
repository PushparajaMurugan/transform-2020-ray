{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unleash the Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dependencies import *\n",
    "from tuning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ray.init(num_cpus=6, num_gpus=0, include_webui=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initialisation the [Ray Dashboard](https://docs.ray.io/en/master/ray-dashboard.html) is available on the **webui_url** port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go Random Go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO replace grid_search\n",
    "\n",
    "Replace grid search with other tune distribution that we can sample from >> [read the docs](https://docs.ray.io/en/latest/tune/api_docs/grid_random.html?highlight=tune.grid#random-distributions-api)\n",
    "\n",
    "Choose appropriate distriutions for the different parameter types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_tuning_config = {\n",
    "    'randomforestclassifier__n_estimators': tune.randint(1, 150),\n",
    "    'randomforestclassifier__criterion': tune.choice(['gini', 'entropy']),\n",
    "    'randomforestclassifier__max_features': tune.choice(['auto', 'sqrt', 'log2']),\n",
    "    'randomforestclassifier__bootstrap': tune.choice([True, False]),\n",
    "    'randomforestclassifier__min_samples_leaf': tune.randint(1,4),\n",
    "    'randomforestclassifier__min_samples_split': tune.randint(3,6)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "                e2e_simple_training,\n",
    "                config=ray_tuning_config,\n",
    "                num_samples=100, # Specify the number of samples to make from (non grid) distributions\n",
    "                resources_per_trial=dict(cpu=1, gpu=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best config: \", analysis.get_best_config(metric=\"mean_f1_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.dataframe()\n",
    "top_n_df = df.nlargest(10, \"mean_f1_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_some_tune_results(top_n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "from tensorboard import notebook \n",
    "%tensorboard --logdir \"~/ray_results/grid_search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exit\n",
    "\n",
    "So what have we just done?\n",
    " - shown how the performance of a model with a single set of hyperparameters affects our score\n",
    " - shown that kfold cv can give us a picture of that distribution which is easier to compute that out-of-bootstrap scores and has less leakage\n",
    " - so which model to choose? == in this case which data split, which is not what we want, we want to chose a robust estimator so we want to find a model with the best score distribution for a given set of hyperparameters\n",
    " - (note: if we want to do hyperparaemter tuning and want our model selection to be unbiaesed weshould do nested Cross Validaiton, but for simpliciy of the code we are sticking with kfold. See: xxxxx_xxxx_xx.ipynb for the nested cross validaiton example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
